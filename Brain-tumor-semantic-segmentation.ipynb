{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:08.106563Z","iopub.status.busy":"2024-01-08T09:58:08.105612Z","iopub.status.idle":"2024-01-08T09:58:22.237578Z","shell.execute_reply":"2024-01-08T09:58:22.236405Z","shell.execute_reply.started":"2024-01-08T09:58:08.106522Z"},"trusted":true},"outputs":[],"source":["! pip install torchview"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:22.240256Z","iopub.status.busy":"2024-01-08T09:58:22.239949Z","iopub.status.idle":"2024-01-08T09:58:28.264627Z","shell.execute_reply":"2024-01-08T09:58:28.26376Z","shell.execute_reply.started":"2024-01-08T09:58:22.240224Z"},"trusted":true},"outputs":[],"source":["import random\n","import os\n","import glob\n","import time\n","import warnings\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","import torchvision\n","import torch.optim.lr_scheduler as lr_scheduler\n","\n","from torch import nn\n","from torch.utils.data import (Dataset, DataLoader)\n","from torchvision import transforms\n","from torchinfo import summary\n","from torchview import draw_graph\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from PIL import Image\n","from tqdm.notebook import tqdm\n","from typing import Dict, List, Tuple\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import (\n","    classification_report, precision_recall_fscore_support,\n","    accuracy_score, f1_score, matthews_corrcoef, \n","    confusion_matrix, ConfusionMatrixDisplay\n",")\n","\n","plt.style.use(\"dark_background\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:28.266418Z","iopub.status.busy":"2024-01-08T09:58:28.265928Z","iopub.status.idle":"2024-01-08T09:58:28.358645Z","shell.execute_reply":"2024-01-08T09:58:28.357902Z","shell.execute_reply.started":"2024-01-08T09:58:28.266389Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    NUM_DEVICES = torch.cuda.device_count()\n","    NUM_WORKERS = os.cpu_count()\n","    \n","    NUM_CLASSES = 2\n","    EPOCHS = 100\n","    BATCH_SIZE = (\n","        32 if torch.cuda.device_count() < 2 \n","        else (32 * torch.cuda.device_count())\n","    )\n","    LR = 1e-4\n","    PATIENS = 8\n","    \n","    APPLY_SHUFFLE = True\n","    SEED = 768\n","    HEIGHT = 224\n","    WIDTH = 224\n","    CHANNELS = 3\n","    IMAGE_SIZE = (224, 224, 3)\n","    \n","    # Define paths\n","    DATASET_PATH = \"/kaggle/input/lgg-mri-segmentation/\"\n","    TRAIN_PATH = '/kaggle/input/lgg-mri-segmentation/kaggle_3m/'\n","    \n","# Mute warnings\n","warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n","warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")"]},{"cell_type":"markdown","metadata":{},"source":["<center><div style='color:#ffffff;\n","           display:inline-block;\n","           padding: 5px 5px 5px 5px;\n","           border-radius:5px;\n","           background-color:#78D1E1;\n","           font-size:100%;'><a href=#toc style='text-decoration: none; color:#03001C;'>⬆️ Back To Top</a></div></center>\n","\n","<a id='1'></a>\n","# 1 | Data Exploration\n","<div style=\"padding: 4px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://i.postimg.cc/j2bBmHWx/Py-Torch-Gradient.jpg); background-size: 100% auto;\"></div>\n","\n","<br>\n","\n","<a id='1.1'></a>\n","### Get image paths with glob"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:28.359964Z","iopub.status.busy":"2024-01-08T09:58:28.359685Z","iopub.status.idle":"2024-01-08T09:58:30.343661Z","shell.execute_reply":"2024-01-08T09:58:30.342775Z","shell.execute_reply.started":"2024-01-08T09:58:28.35994Z"},"trusted":true},"outputs":[],"source":["%%time\n","dataset_images = glob.glob(f\"{CFG.TRAIN_PATH}**/*.tif\")\n","dataset_images[:5]"]},{"cell_type":"markdown","metadata":{},"source":["<a id='1.2'></a>\n","### Create Pandas DataFrames for images and masks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:30.346295Z","iopub.status.busy":"2024-01-08T09:58:30.346007Z","iopub.status.idle":"2024-01-08T09:58:30.356424Z","shell.execute_reply":"2024-01-08T09:58:30.355357Z","shell.execute_reply.started":"2024-01-08T09:58:30.34627Z"},"trusted":true},"outputs":[],"source":["def get_sample_patient_id(image_paths):\n","    return [(_.split('/')[-2:][0]) for _ in image_paths]\n","\n","\n","def get_sample_number(image_paths):\n","    sample_numbers = []\n","    is_mask = []\n","    \n","    for path in image_paths:\n","        path_list = path.split('/')[-2:][1].split('_')\n","\n","        if 'mask.tif' in path_list:\n","            sample_numbers.append(int(path_list[-2]))\n","            is_mask.append(1)\n","        else:\n","            sample_numbers.append(int(path_list[-1].replace('.tif', '')))\n","            is_mask.append(0)\n","            \n","    return sample_numbers, is_mask\n","\n","\n","def build_df(image_paths):\n","    sample_numbers, mask_label = get_sample_number(image_paths)\n","    # Create dataframe\n","    df = pd.DataFrame({\n","        'id'        : sample_numbers,\n","        'patient'   : get_sample_patient_id(image_paths),\n","        'image_path': image_paths,\n","        'is_mask'   : mask_label\n","    })\n","    \n","    # Return df\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:30.35771Z","iopub.status.busy":"2024-01-08T09:58:30.357455Z","iopub.status.idle":"2024-01-08T09:58:30.444658Z","shell.execute_reply":"2024-01-08T09:58:30.443804Z","shell.execute_reply.started":"2024-01-08T09:58:30.357688Z"},"trusted":true},"outputs":[],"source":["dataset_df = (\n","    build_df(dataset_images)\n","    .sort_values(by=['id', 'patient', 'image_path'])\n","    .reset_index(drop=True)\n",")\n","\n","dataset_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:30.44662Z","iopub.status.busy":"2024-01-08T09:58:30.446003Z","iopub.status.idle":"2024-01-08T09:58:30.466979Z","shell.execute_reply":"2024-01-08T09:58:30.466096Z","shell.execute_reply.started":"2024-01-08T09:58:30.446584Z"},"trusted":true},"outputs":[],"source":["# Group Samples by mask status\n","grouped_df = dataset_df.groupby(by='is_mask')\n","\n","# Seperate Images from Masks\n","images_df, mask_df = (\n","    grouped_df.get_group(0).drop('is_mask', axis=1).reset_index(drop=True), \n","    grouped_df.get_group(1).drop('is_mask', axis=1).reset_index(drop=True)\n",")\n","\n","# Rename path column in mask df\n","mask_df = mask_df.rename({'image_path': 'mask_path'}, axis=1)\n","\n","# View mask df\n","mask_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:30.468256Z","iopub.status.busy":"2024-01-08T09:58:30.467978Z","iopub.status.idle":"2024-01-08T09:58:30.47384Z","shell.execute_reply":"2024-01-08T09:58:30.472863Z","shell.execute_reply.started":"2024-01-08T09:58:30.468232Z"},"trusted":true},"outputs":[],"source":["def _load(image_path, as_tensor=True):\n","    image = Image.open(image_path)\n","    return np.array(image).astype(np.float32) / 255.\n","\n","\n","def generate_label(mask_path, load_fn):\n","    mask = load_fn(mask_path)\n","    if mask.max() > 0:\n","        return 1 # Brain Tumor Present\n","    return 0 # Normal"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:30.475296Z","iopub.status.busy":"2024-01-08T09:58:30.47503Z","iopub.status.idle":"2024-01-08T09:58:51.67701Z","shell.execute_reply":"2024-01-08T09:58:51.675985Z","shell.execute_reply.started":"2024-01-08T09:58:30.475274Z"},"trusted":true},"outputs":[],"source":["# Merge images and mask df's\n","ds = images_df.merge(\n","    mask_df,\n","    on=['id', 'patient'],\n","    how='left'\n",")\n","\n","# Generate MRI Label\n","ds['diagnosis'] = [generate_label(_, _load) for _ in tqdm(ds['mask_path'])]\n","ds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:58:51.678409Z","iopub.status.busy":"2024-01-08T09:58:51.678151Z","iopub.status.idle":"2024-01-08T09:58:51.994843Z","shell.execute_reply":"2024-01-08T09:58:51.993816Z","shell.execute_reply.started":"2024-01-08T09:58:51.678386Z"},"trusted":true},"outputs":[],"source":["# View Diagnosis Distribution\n","fig = plt.figure(figsize=(15, 8))\n","plt.title('Diagnosis Distribution', fontsize=22);\n","\n","diagnosis_distribution = ds['diagnosis'].value_counts().sort_values()\n","diagnosis_map = {0: 'Normal', 1: 'Tumor'}\n","\n","bar_plot = sns.barplot(\n","    x=diagnosis_distribution.values,\n","    y=[diagnosis_map[_] for _ in diagnosis_distribution.keys()],\n","    palette=sns.color_palette(\"plasma\"),\n","    orient=\"h\"\n",");\n","\n","for container in bar_plot.containers:\n","    bar_plot.bar_label(container, fmt='%.0f', fontsize=14);\n","    \n","plt.xticks(fontsize=14);\n","plt.yticks(fontsize=14);\n","\n","text_params = {\n","    'x'       : 2400,\n","    'y'       : -0.4,\n","    's'       : f\"Total {len(ds)} images\", \n","    'size'    : 12,\n","    'color'   : \"black\",\n","    'ha'      : \"center\", \n","    'va'      : \"center\",\n","    'bbox'    : dict(boxstyle=\"round\", fc=(\"lightgreen\"),ec=(\"black\"))\n","}\n","plt.text(**text_params);\n","\n","sns.despine();"]},{"cell_type":"markdown","metadata":{},"source":["<a id='1.3'></a>\n","### Load & View Random Sample"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:33:43.3502Z","iopub.status.busy":"2024-01-08T11:33:43.349689Z","iopub.status.idle":"2024-01-08T11:33:43.359446Z","shell.execute_reply":"2024-01-08T11:33:43.358363Z","shell.execute_reply.started":"2024-01-08T11:33:43.350163Z"},"trusted":true},"outputs":[],"source":["def view_sample(image, mask, color_map='rgb', fig_size=(16, 8), title_size=18):\n","    fig = plt.figure(figsize=fig_size);\n","    fig.tight_layout();\n","    fig.subplots_adjust(top=0.95);\n","    \n","    # Plot MRI Image\n","    plt.subplot(1, 3, 1);\n","    plt.title(f'MRI Image', fontsize=title_size)\n","    if color_map=='rgb':\n","        plt.imshow(image)\n","    else:\n","        plt.imshow(image, cmap=color_map)\n","        \n","    # Plot Mask\n","    plt.subplot(1, 3, 2);\n","    plt.title(f'Mask', fontsize=title_size)\n","    plt.imshow(mask, cmap='gray');\n","    \n","    # Plot MRI w. Mask \n","    plt.subplot(1, 3, 3);\n","    plt.title(f'MRI + Mask', fontsize=title_size)\n","    gen_mask = np.dstack([mask*0.1, mask*0.4, mask*0.1])\n","    \n","    if color_map=='rgb':\n","        plt.imshow(image + gen_mask, interpolation='none')\n","    else:\n","        plt.imshow(image + gen_mask, interpolation='none', cmap=color_map)\n","        \n","#     plt.imshow(mask, cmap='jet', interpolation='none', alpha=0.4);\n","    \n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:33:52.217967Z","iopub.status.busy":"2024-01-08T11:33:52.21759Z","iopub.status.idle":"2024-01-08T11:33:53.080563Z","shell.execute_reply":"2024-01-08T11:33:53.079671Z","shell.execute_reply.started":"2024-01-08T11:33:52.217939Z"},"trusted":true},"outputs":[],"source":["# Select random sample from train_df\n","idx = random.sample(ds.index.to_list(), 1)[0]\n","\n","# Load the random sample and label\n","sample_image, sample_mask = _load(ds.image_path[idx]), _load(ds.mask_path[idx])\n","\n","# View the random sample\n","view_sample(\n","    sample_image,\n","    sample_mask,\n","    color_map='rgb',\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<a id='1.4'></a>\n","### Load & View Multiple Random Samples"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:33:35.894655Z","iopub.status.busy":"2024-01-08T11:33:35.89426Z","iopub.status.idle":"2024-01-08T11:33:40.478337Z","shell.execute_reply":"2024-01-08T11:33:40.477404Z","shell.execute_reply.started":"2024-01-08T11:33:35.894623Z"},"trusted":true},"outputs":[],"source":["def view_mulitiple_samples(df, sample_loader, count=10, color_map='rgb', fig_size=(14, 10), title_size=16):\n","    idx = random.sample(df.index.to_list(), count)\n","    \n","    fig = plt.figure(figsize=fig_size);\n","    fig.tight_layout();\n","    fig.subplots_adjust(top=0.95);\n","\n","    for row, _ in enumerate(idx):\n","        image, mask = (\n","            sample_loader(df.image_path[_]),#.permute(1, 2, 0),\n","            sample_loader(df.mask_path[_])#.permute(1, 2, 0)\n","        )\n","        \n","        idx = 3 * (row + 1)\n","        # Plot MRI Image\n","        plt.subplot(count+1, 3, idx + 1);\n","        plt.title(f'MRI Image', fontsize=title_size);\n","        if color_map=='rgb':\n","            plt.imshow(image)\n","        else:\n","            plt.imshow(image, cmap=color_map)\n","\n","        # Plot Mask\n","        plt.subplot(count+1, 3, idx + 2);\n","        plt.title(f'Mask', fontsize=title_size)\n","        plt.imshow(mask, cmap='gray');\n","\n","        # Plot MRI w. Mask \n","        plt.subplot(count+1, 3, idx + 3);\n","        gen_mask = np.dstack([mask*0.1, mask*0.4, mask*0.1])\n","        plt.title(f'MRI + Mask', fontsize=title_size)\n","        if color_map=='rgb':\n","            plt.imshow(image + gen_mask)\n","        else:\n","            plt.imshow(image + gen_mask, cmap=color_map)\n","\n","#         plt.imshow(mask, cmap='gray', alpha=0.5);\n","\n","    return\n","\n","# View 6 random sample images\n","view_mulitiple_samples(\n","    ds, _load, \n","    count=6, color_map='mako',\n","    fig_size=(18, 30)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<a id='1.5'></a>\n","### Create Train, Validation and Test sets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:26:32.082001Z","iopub.status.busy":"2024-01-08T10:26:32.081631Z","iopub.status.idle":"2024-01-08T10:26:32.101662Z","shell.execute_reply":"2024-01-08T10:26:32.100719Z","shell.execute_reply.started":"2024-01-08T10:26:32.081973Z"},"trusted":true},"outputs":[],"source":["# Create Train split \n","train_split_idx, data_split_idx, _, _ = (\n","    train_test_split(\n","        ds.index, \n","        ds.diagnosis, \n","        test_size=0.30,\n","        stratify=ds.diagnosis,\n","        random_state=CFG.SEED\n","    )\n",")\n","\n","# Get training and remaining data\n","train_df = ds.iloc[train_split_idx].reset_index(drop=True)\n","data_df = ds.iloc[data_split_idx].reset_index(drop=True)\n","\n","# View shapes\n","train_df.shape, data_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:26:37.221575Z","iopub.status.busy":"2024-01-08T10:26:37.220784Z","iopub.status.idle":"2024-01-08T10:26:37.234509Z","shell.execute_reply":"2024-01-08T10:26:37.233498Z","shell.execute_reply.started":"2024-01-08T10:26:37.221542Z"},"trusted":true},"outputs":[],"source":["# Create Val/Test split \n","val_split_idx, test_split_idx, _, _ = (\n","    train_test_split(\n","        data_df.index, \n","        data_df.diagnosis, \n","        test_size=0.65,\n","        stratify=data_df.diagnosis,\n","        random_state=CFG.SEED\n","    )\n",")\n","\n","# Get training and remaining data\n","val_df = data_df.iloc[val_split_idx].reset_index(drop=True)\n","test_df = data_df.iloc[test_split_idx].reset_index(drop=True)\n","\n","# View shapes\n","val_df.shape, test_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:26:39.448796Z","iopub.status.busy":"2024-01-08T10:26:39.448402Z","iopub.status.idle":"2024-01-08T10:26:39.455417Z","shell.execute_reply":"2024-01-08T10:26:39.45444Z","shell.execute_reply.started":"2024-01-08T10:26:39.448759Z"},"trusted":true},"outputs":[],"source":["train_size = len(train_df)\n","val_size = len(val_df)\n","test_size = len(test_df)\n","total = train_size + val_size + test_size\n","\n","# View the counts\n","print(f'train samples count:\\t\\t{train_size}\\t({(100 * train_size/total):.2f}%)')\n","print(f'validation samples count:\\t{val_size}\\t({(100 * val_size/total):.2f}%)')\n","print(f'test samples count:\\t\\t{test_size}\\t({(100 * test_size/total):.2f}%)')\n","print('================================================')\n","print(f'TOTAL:\\t\\t\\t\\t{total}\\t({(100 * total/total):.2f}%)')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:26:42.668214Z","iopub.status.busy":"2024-01-08T10:26:42.667861Z","iopub.status.idle":"2024-01-08T10:26:43.449566Z","shell.execute_reply":"2024-01-08T10:26:43.448665Z","shell.execute_reply.started":"2024-01-08T10:26:42.668186Z"},"trusted":true},"outputs":[],"source":["fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(16, 18))\n","\n","# Set the spacing between subplots\n","fig.tight_layout(pad=6.0)\n","sns.despine();\n","\n","\n","# Plot Train Labels Distribution\n","ax1.set_title('Train Labels Distribution', fontsize=24)\n","train_distribution = train_df['diagnosis'].value_counts().sort_values()\n","labels = {0: 'NORMAL', 1: 'TUMOR'}\n","bar_plot = sns.barplot(\n","    x=train_distribution.values,\n","    y=[labels[_] for _ in train_distribution.keys()],\n","    orient=\"h\", palette=sns.color_palette(\"plasma\"),\n","    ax=ax1\n",");\n","\n","for container in bar_plot.containers:\n","    bar_plot.bar_label(container, fmt='%.0f', fontsize=14);\n","\n","# Update axes tick parameters\n","ax1.tick_params(\n","    axis='both', which='major', \n","    labelsize=16\n",");\n","\n","# Plot Validation Labels Distribution\n","ax2.set_title('Validation Labels Distribution', fontsize=24)\n","val_distribution = val_df['diagnosis'].value_counts().sort_values()\n","\n","bar_plot = sns.barplot(\n","    x=val_distribution.values,\n","    y=[labels[_] for _ in val_distribution.keys()],\n","    orient=\"h\", palette=sns.color_palette(\"plasma\"),\n","    ax=ax2\n",");\n","\n","for container in bar_plot.containers:\n","    bar_plot.bar_label(container, fmt='%.0f', fontsize=14);\n","\n","# Update axes tick parameters\n","ax2.tick_params(\n","    axis='both', which='major', \n","    labelsize=16\n",");\n","    \n","# Plot Test Labels Distribution\n","ax3.set_title('Test Labels Distribution', fontsize=24)\n","test_distribution = test_df['diagnosis'].value_counts().sort_values()\n","\n","bar_plot = sns.barplot(\n","    x=test_distribution.values,\n","    y=[labels[_] for _ in test_distribution.keys()],\n","    orient=\"h\", palette=sns.color_palette(\"plasma\"),\n","    ax=ax3\n",");\n","\n","for container in bar_plot.containers:\n","    bar_plot.bar_label(container, fmt='%.0f', fontsize=14);\n","    \n","# Update axes tick parameters\n","ax3.tick_params(\n","    axis='both', which='major', \n","    labelsize=16\n",");"]},{"cell_type":"markdown","metadata":{},"source":["<center><div style='color:#ffffff;\n","           display:inline-block;\n","           padding: 5px 5px 5px 5px;\n","           border-radius:5px;\n","           background-color:#78D1E1;\n","           font-size:100%;'><a href=#toc style='text-decoration: none; color:#03001C;'>⬆️ Back To Top</a></div></center>\n","\n","<a id='2'></a>\n","# 2 | Build Custom Datasets & DataLoaders\n","<div style=\"padding: 4px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://i.postimg.cc/j2bBmHWx/Py-Torch-Gradient.jpg); background-size: 100% auto;\"></div>\n","\n","<br>\n","\n","In order to train the model, we need to setup an input pipeline to load, preprocess and feed the input images to the model. This pipeline is required as loading all images at once into memory may cause an out of memory error to be raised. We also batch load images for efficient memory allocation.\n","\n","For this pipeline, we'll use PyTorch's data API to contruct a dataloader and custom dataset/pipeline to load our images into memory for training and inference. We'll also use the transforms API from PyTorch's torchvision library to handle image augmentations for the training set images.\n","\n","> See the following for more information:\n","> - [PyTorch | Transforming and Augmenting Images](https://pytorch.org/vision/stable/transforms.html)\n","> - [PyTorch | Datasets & Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n","> - [PyTorch | Data API](https://pytorch.org/docs/stable/data.html)\n","\n","<br>\n","\n","<a id='2.1'></a>\n","### Define & Inspect Image Transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:26:51.487154Z","iopub.status.busy":"2024-01-08T10:26:51.486407Z","iopub.status.idle":"2024-01-08T10:26:51.494004Z","shell.execute_reply":"2024-01-08T10:26:51.492892Z","shell.execute_reply.started":"2024-01-08T10:26:51.487114Z"},"trusted":true},"outputs":[],"source":["# Augment train data\n","train_transforms = A.Compose([\n","    A.Resize(CFG.HEIGHT, CFG.WIDTH, p=1.0),\n","    A.RandomBrightnessContrast(p=0.2),\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    ToTensorV2(),\n","])\n","\n","# Only reshape inference data\n","inference_transforms = A.Compose([\n","    A.Resize(CFG.HEIGHT, CFG.WIDTH, p=1.0),\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:26:54.476563Z","iopub.status.busy":"2024-01-08T10:26:54.476235Z","iopub.status.idle":"2024-01-08T10:26:55.898552Z","shell.execute_reply":"2024-01-08T10:26:55.897659Z","shell.execute_reply.started":"2024-01-08T10:26:54.476538Z"},"trusted":true},"outputs":[],"source":["# Select random sample from train_df\n","idx = random.sample(ds.index.to_list(), 1)[0]\n","\n","# Load the random sample and label\n","sample_image, sample_mask = _load(ds.image_path[idx]), _load(ds.mask_path[idx])\n","\n","aug = train_transforms(image=sample_image, mask=sample_mask)\n","\n","# View the random sample\n","view_sample(\n","    aug['image'].permute(1, 2, 0),\n","    aug['mask'].unsqueeze_(0).permute(1, 2, 0),\n","    color_map='mako',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:26:56.568611Z","iopub.status.busy":"2024-01-08T10:26:56.568259Z","iopub.status.idle":"2024-01-08T10:26:56.579807Z","shell.execute_reply":"2024-01-08T10:26:56.578871Z","shell.execute_reply.started":"2024-01-08T10:26:56.568582Z"},"trusted":true},"outputs":[],"source":["class MRISegmetationDataset(Dataset):\n","    def __init__(self, df:pd.DataFrame, transform=None) -> None:\n","        super().__init__()\n","        \n","        self.mri_paths = df['image_path'].to_list()\n","        self.mask_paths = df['mask_path'].to_list()\n","#         self.labels = df['diagnosis'].to_list()\n","        self.transform = transform\n","        \n","#         self.classes = sorted(list(df['diagnosis'].unique()))\n","#         self.class_to_idx = {cls_name: _ for _, cls_name in enumerate(self.classes)}\n","        \n","    def load_sample(self, index:str) -> Image.Image:\n","        image_path = self.mri_paths[index]\n","        mask_path = self.mask_paths[index]\n","        \n","        image, mask = Image.open(image_path), Image.open(mask_path)\n","        \n","        image = np.array(image).astype(np.float32) / 255.\n","        mask = np.array(mask).astype(np.float32) / 255.\n","        \n","        return image, mask\n","        \n","    def __len__(self) -> int:\n","        return self.mri_paths.__len__()\n","    \n","    def __getitem__(self, index:int) -> Tuple[torch.Tensor, torch.Tensor]:\n","        image, mask = self.load_sample(index)\n","        \n","        # Transform if necessary\n","        if self.transform:\n","            transformed = self.transform(image=image, mask=mask)\n","            return transformed['image'], transformed['mask'].unsqueeze_(0)\n","        else:\n","            transformed = ToTensorV2()(image=image, mask=mask)    \n","            return transformed['image'], transformed['mask'].unsqueeze_(0)"]},{"cell_type":"markdown","metadata":{},"source":["<a id='2.2'></a>\n","### Build Custom Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:00.312817Z","iopub.status.busy":"2024-01-08T10:27:00.312448Z","iopub.status.idle":"2024-01-08T10:27:00.318419Z","shell.execute_reply":"2024-01-08T10:27:00.317399Z","shell.execute_reply.started":"2024-01-08T10:27:00.312787Z"},"trusted":true},"outputs":[],"source":["# Build train dataset\n","train_ds = MRISegmetationDataset(\n","    train_df, transform=train_transforms\n",")\n","\n","# Build validation dataset\n","val_ds = MRISegmetationDataset(\n","    val_df, transform=inference_transforms\n",")\n","\n","# Build test dataset\n","test_ds = MRISegmetationDataset(\n","    test_df, transform=inference_transforms\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<a id='2.3'></a>\n","### Build DataLoaders from Custom Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:02.596192Z","iopub.status.busy":"2024-01-08T10:27:02.59544Z","iopub.status.idle":"2024-01-08T10:27:02.601869Z","shell.execute_reply":"2024-01-08T10:27:02.601007Z","shell.execute_reply.started":"2024-01-08T10:27:02.596158Z"},"trusted":true},"outputs":[],"source":["# Build train dataloader\n","train_loader = DataLoader(\n","    dataset=train_ds, \n","    batch_size=CFG.BATCH_SIZE,\n","    num_workers=CFG.NUM_WORKERS,\n","    shuffle=CFG.APPLY_SHUFFLE\n",")\n","\n","# Build validation dataloader\n","val_loader = DataLoader(\n","    dataset=val_ds, \n","    batch_size=CFG.BATCH_SIZE,\n","    num_workers=CFG.NUM_WORKERS,\n","    shuffle=False\n",")\n","\n","# Build test dataloader\n","test_loader = DataLoader(\n","    dataset=test_ds, \n","    batch_size=CFG.BATCH_SIZE,\n","    num_workers=CFG.NUM_WORKERS,\n","    shuffle=False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<center><div style='color:#ffffff;\n","           display:inline-block;\n","           padding: 5px 5px 5px 5px;\n","           border-radius:5px;\n","           background-color:#78D1E1;\n","           font-size:100%;'><a href=#toc style='text-decoration: none; color:#03001C;'>⬆️ Back To Top</a></div></center>\n","\n","<a id='3'></a>\n","# 3 | Write Custom Training Functions\n","<div style=\"padding: 4px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://i.postimg.cc/j2bBmHWx/Py-Torch-Gradient.jpg); background-size: 100% auto;\"></div>\n","\n","<br>\n","\n","<a id='3.1'></a>\n","### Define Epoch Execution (Train Step)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:05.045619Z","iopub.status.busy":"2024-01-08T10:27:05.044757Z","iopub.status.idle":"2024-01-08T10:27:05.05465Z","shell.execute_reply":"2024-01-08T10:27:05.053682Z","shell.execute_reply.started":"2024-01-08T10:27:05.045586Z"},"trusted":true},"outputs":[],"source":["def execute_epoch(\n","    model:torch.nn.Module,\n","    dataloader:torch.utils.data.DataLoader,\n","    optimizer:torch.optim.Optimizer,\n","    loss_fn:torch.nn.Module,\n","    device:torch.device) -> Tuple[float, float]:\n","    \n","    # Set model into training mode\n","    model.train()\n","    \n","    # Initialize train loss & accuracy\n","    train_loss, train_dice = 0, 0\n","    \n","    # Execute training loop over train dataloader\n","    for batch, (X, y) in enumerate(tqdm(dataloader)):\n","        # Load data onto target device\n","        X, y = X.to(device), y.to(device)\n","        \n","        # Feed-forward and compute metrics\n","        y_pred = model(X)\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item() \n","        \n","        # Reset Gradients & Backpropagate Loss\n","        optimizer.zero_grad()\n","        loss.backward()\n","        \n","        # Update Model Gradients\n","        optimizer.step()\n","        \n","        # Compute Batch Metrics\n","        predicted_class = torch.sigmoid(y_pred)\n","        predicted_class = (predicted_class > 0.5).float()\n","        \n","        eps = 1e-8\n","        train_dice += (\n","            (2 * (y * predicted_class).sum() + eps) / \n","            ((y + predicted_class).sum() + eps)\n","        ).cpu().item()\n","        \n","        \n","    # Compute Step Metrics\n","    train_loss = train_loss / len(dataloader)\n","    train_dice = train_dice / len(dataloader)\n","    \n","    return train_loss, train_dice"]},{"cell_type":"markdown","metadata":{},"source":["<a id='3.2'></a>\n","### Define Evaluation Step"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:08.154934Z","iopub.status.busy":"2024-01-08T10:27:08.154201Z","iopub.status.idle":"2024-01-08T10:27:08.163451Z","shell.execute_reply":"2024-01-08T10:27:08.162533Z","shell.execute_reply.started":"2024-01-08T10:27:08.154901Z"},"trusted":true},"outputs":[],"source":["def evaluate(\n","    model:torch.nn.Module,\n","    dataloader:torch.utils.data.DataLoader,\n","    loss_fn:torch.nn.Module,\n","    device:torch.device) -> Tuple[float, float]:\n","    \n","    # Set model into eval mode\n","    model.eval()\n","    \n","    # Initialize eval loss & accuracy\n","    eval_loss, eval_dice = 0, 0\n","    \n","    # Active inferene context manager\n","    with torch.inference_mode():\n","        # Execute eval loop over dataloader\n","        for batch, (X, y) in enumerate(dataloader):\n","            # Load data onto target device\n","            X, y = X.to(device), y.to(device)\n","\n","            # Feed-forward and compute metrics\n","            y_pred = model(X)\n","            loss = loss_fn(y_pred, y)\n","            eval_loss += loss.item() \n","\n","            # Compute Batch Metrics\n","            predicted_class = torch.sigmoid(y_pred)\n","            predicted_class = (predicted_class > 0.5).float()\n","            \n","            eps = 1e-8\n","            eval_dice += (\n","                (2 * (y * predicted_class).sum() + eps) / \n","                ((y + predicted_class).sum() + eps)\n","            ).cpu().item()\n","            \n","    # Compute Step Metrics\n","    eval_loss = eval_loss / len(dataloader)\n","    eval_dice = eval_dice / len(dataloader)\n","    \n","    return eval_loss, eval_dice"]},{"cell_type":"markdown","metadata":{},"source":["<a id='3.3'></a>\n","### Construct Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:10.325016Z","iopub.status.busy":"2024-01-08T10:27:10.324625Z","iopub.status.idle":"2024-01-08T10:27:10.336413Z","shell.execute_reply":"2024-01-08T10:27:10.335446Z","shell.execute_reply.started":"2024-01-08T10:27:10.324985Z"},"trusted":true},"outputs":[],"source":["def train(\n","    model:torch.nn.Module,\n","    train_dataloader:torch.utils.data.DataLoader,\n","    eval_dataloader:torch.utils.data.DataLoader,\n","    optimizer:torch.optim.Optimizer,\n","    scheduler:torch.optim.lr_scheduler,\n","    loss_fn:torch.nn.Module,\n","    epochs:int,\n","    device:torch.device) -> Dict[str, List]:\n","    \n","    # Initialize training session\n","    session = {\n","        'loss'            : [],\n","        'dice_score'      : [],\n","        'eval_loss'       : [],\n","        'eval_dice_score' : []\n","    }\n","    \n","    # Training loop\n","    for epoch in tqdm(range(epochs)):\n","        # Execute Epoch\n","        print(f'\\nEpoch {epoch + 1}/{epochs}')\n","        train_loss, train_dice = execute_epoch(\n","            model, \n","            train_dataloader, \n","            optimizer, \n","            loss_fn, \n","            device\n","        )\n","        \n","        # Evaluate Model\n","        eval_loss, eval_dice = evaluate(\n","            model, \n","            eval_dataloader,\n","            loss_fn, \n","            device\n","        )\n","        \n","        # Execute schedular step\n","        current_lr = 0\n","        if scheduler: \n","            scheduler.step(eval_loss)\n","            current_lr = optimizer.param_groups[0]['lr']\n","        \n","        # Log Epoch Metrics\n","        log_text = f'loss: {train_loss:.4f} - dice_score: {train_dice:.4f} - eval_loss: {eval_loss:.4f} - eval_dice_score: {eval_dice:.4f}'\n","        \n","        if scheduler: \n","            print(log_text + f' - lr: {current_lr}')\n","        else:\n","            print(log_text)\n","            \n","        # Record Epoch Metrics\n","        session['loss'].append(train_loss)\n","        session['dice_score'].append(train_dice)\n","        session['eval_loss'].append(eval_loss)\n","        session['eval_dice_score'].append(eval_dice)\n","        \n","    # Return Session Metrics\n","    return session"]},{"cell_type":"markdown","metadata":{},"source":["<a id='3.4'></a>\n","### Construct Predict Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:12.774106Z","iopub.status.busy":"2024-01-08T10:27:12.773722Z","iopub.status.idle":"2024-01-08T10:27:12.781952Z","shell.execute_reply":"2024-01-08T10:27:12.780921Z","shell.execute_reply.started":"2024-01-08T10:27:12.774076Z"},"trusted":true},"outputs":[],"source":["def predict(\n","    model:nn.Module, \n","    sample_loader:torch.utils.data.DataLoader,\n","    device:torch.device,\n","    threshold:float=0.5) -> np.ndarray:\n","    \n","    # Set model into eval mode\n","    model.eval()\n","    \n","    predictions = []\n","    \n","    # Active inferene context manager\n","    with torch.inference_mode():\n","        # Execute eval loop over dataloader\n","        for batch, (X, y) in enumerate(tqdm(sample_loader)):\n","            # Load data onto target device\n","            X, y = X.to(device), y.to(device)\n","\n","            # Feed-forward and compute metrics\n","            y_pred = model(X) \n","\n","            # Compute Batch Metrics\n","            predicted_class = torch.sigmoid(y_pred)\n","            predicted_class = (predicted_class >= threshold).float()\n","\n","            # Record prediction\n","            predictions.append(predicted_class.cpu().numpy())\n","        \n","    return np.vstack(predictions)"]},{"cell_type":"markdown","metadata":{},"source":["<center><div style='color:#ffffff;\n","           display:inline-block;\n","           padding: 5px 5px 5px 5px;\n","           border-radius:5px;\n","           background-color:#78D1E1;\n","           font-size:100%;'><a href=#toc style='text-decoration: none; color:#03001C;'>⬆️ Back To Top</a></div></center>\n","\n","<a id='4'></a>\n","# 4 | Implementing U-Net Architecture (Research Paper)\n","<div style=\"padding: 4px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://i.postimg.cc/j2bBmHWx/Py-Torch-Gradient.jpg); background-size: 100% auto;\"></div>\n","\n","<br>\n"," \n","The U-Net architecture, which was introduced in 2015, has been a game-changer in the field of deep learning. The architecture won the International Syposium on Biomedical Imaging (ISBI) cell tracking challenge conducted in 2015 by a significant margin in several categories such as phase constrast and DIC microscopy, both of which fall under the transmitted light microscopy tasks.\n","\n","<br>\n","\n","<center>\n","    <figure>\n","        <img src=\"https://i.postimg.cc/Pxz6NFjw/UNet-Architecture.png\" alt =\"U-Net Architecture\" style='width:75%;'>\n","        <figcaption>\n","            Source: U-Net architecture diagram from <a href=\"https://arxiv.org/pdf/1505.04597.pdf\">paper</a>.\n","        </figcaption>\n","    </figure>\n","</center>\n","\n","<br>\n","\n","\n","The architecture is comprised of two paths - the contracting path (on the left) and the expansive path (on the right). The contracting path (encoder) adheres to the conventional architecture of a convolutional network. It consists of repeatedly applying blocks of two 3x3 convolutions (without padding), followed by a rectified linear unit (ReLU) and a 2x2 max pooling (with stride 2) operation that reduces the size of the features by half. At each downsampling step, the number of feature channels is doubled. We will refer to these blocks as Double Convolutional blocks.\n","\n","\n","Each step in the expansive path (decoder) involves upsampling the feature map, followed by a 2x2 convolution (known as an \"up-convolution\") that reduces the number of feature channels by half. This is then concatenated with the feature map from the contracting path that has been correspondingly cropped, and two 3x3 convolutions are applied to it, each followed by a ReLU activation. The cropping is necessary due to the border pixels that are lost at every convolution. At the final layer, a 1x1 convolution is utilized to map each 64-component feature vector to the desired number of classes."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-01-08T10:27:15.526641Z","iopub.status.busy":"2024-01-08T10:27:15.525691Z","iopub.status.idle":"2024-01-08T10:27:15.534269Z","shell.execute_reply":"2024-01-08T10:27:15.533218Z","shell.execute_reply.started":"2024-01-08T10:27:15.526605Z"},"trusted":true},"outputs":[],"source":["from IPython.display import HTML\n","html_embed = \"\"\"\n","<iframe \n","    width=\"700\" height=\"400\" \n","    src=\"https://www.youtube.com/embed/81AvQQnpG4Q?si=q4jCb6CHqPWNGZ8u\" \n","    title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; \n","    autoplay; clipboard-write; encrypted-media; \n","    gyroscope; picture-in-picture; \n","    web-share\" allowfullscreen>\n","</iframe>\n","\"\"\"\n","\n","HTML(f'<div align=\"center\">{html_embed}</div>')"]},{"cell_type":"markdown","metadata":{},"source":["In this section we will implement, generate and visualize the U-Net architecture in PyTorch.\n","\n","For more information, kindly see the following:\n","> - [arXiv | U-Net Architecture Paper](https://arxiv.org/abs/1505.04597)\n","> - [Freinburg University | U-Net: Convolutional Networks for Biomedical Image Segmentation](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n","> - [SuperAnnotate | Complete guide to semantic segmentation [Updated 2023]](https://www.superannotate.com/blog/guide-to-semantic-segmentation)\n","\n","<br>\n","\n","<a id='4.1'></a>\n","### Define Double Convolution Block"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:19.055931Z","iopub.status.busy":"2024-01-08T10:27:19.055528Z","iopub.status.idle":"2024-01-08T10:27:19.064649Z","shell.execute_reply":"2024-01-08T10:27:19.063526Z","shell.execute_reply.started":"2024-01-08T10:27:19.055899Z"},"trusted":true},"outputs":[],"source":["class DoubleConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConvBlock, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(\n","            in_channels, out_channels, \n","            kernel_size=3, stride=1, \n","            padding=1, bias=False\n","        )\n","        self.conv2 = nn.Conv2d(\n","            out_channels, out_channels, \n","            kernel_size=3, stride=1, \n","            padding=1, bias=False\n","        )\n","\n","        self.batchnorm1 = nn.BatchNorm2d(out_channels)\n","        self.batchnorm2 = nn.BatchNorm2d(out_channels)\n","        \n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.relu2 = nn.ReLU(inplace=True)\n","        \n","        \n","    def forward(self, x):\n","        # First Convolution\n","        x = self.conv1(x)\n","        x = self.batchnorm1(x)\n","        x = self.relu1(x)\n","        \n","        # Second Convolution\n","        x = self.conv2(x)\n","        x = self.batchnorm2(x)\n","        \n","        return self.relu2(x)"]},{"cell_type":"markdown","metadata":{},"source":["<a id='4.2'></a>\n","### Implement U-Net Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:21.398714Z","iopub.status.busy":"2024-01-08T10:27:21.397977Z","iopub.status.idle":"2024-01-08T10:27:21.411263Z","shell.execute_reply":"2024-01-08T10:27:21.410279Z","shell.execute_reply.started":"2024-01-08T10:27:21.398683Z"},"trusted":true},"outputs":[],"source":["class UNetModel(nn.Module):\n","    def __init__(\n","        self, in_channels:int=3, \n","        out_channels:int=1, \n","        block_sizes:Tuple[int]=(64, 128, 256, 512)\n","    ):\n","        super(UNetModel, self).__init__()\n","        # Initialise model encoder & decoder using torch ModuleLists\n","        self.encoder, self.decoder = nn.ModuleList(), nn.ModuleList()\n","        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2) \n","        \n","        # Create Encoder\n","        for block_size in block_sizes:\n","            self.encoder.append(DoubleConvBlock(in_channels, block_size))\n","            in_channels = block_size\n","            \n","        # Create Decoder\n","        for block_size in block_sizes[::-1]:\n","            self.decoder.append(\n","                nn.ConvTranspose2d(2 * block_size, block_size, kernel_size=2, stride=2)\n","            )\n","            self.decoder.append(DoubleConvBlock(2 * block_size, block_size))\n","        \n","        # Create Bottleneck\n","        last_blocksize = block_sizes[-1]\n","        self.bottleneck = DoubleConvBlock(last_blocksize, 2 * last_blocksize)\n","        \n","        # Create Output Layer\n","        self.output_conv = nn.Conv2d(block_sizes[0], out_channels, kernel_size=1)\n","        \n","    def forward(self, x):\n","        concatenations = []\n","        concatenations.append(x)\n","        \n","        # Propagate input downstream (Encode Input)\n","        for encoder_layer in self.encoder:\n","            x = encoder_layer(x)\n","            concatenations.append(x)\n","            x = self.max_pool(x)\n","            \n","        # Execute bottleneck\n","        x = self.bottleneck(x)\n","        concatenations = concatenations[::-1]\n","        \n","        # Propagate input upstream (Decode Input) & concatenate layers\n","        for _ in range(0, len(self.decoder), 2):\n","            x = self.decoder[_](x)\n","            encoder_layer = concatenations[_ // 2]\n","            \n","            # Concatenate corrensponding encoder layer to decoder layer output\n","            concat_layer = torch.cat(\n","                (encoder_layer, x), dim=1\n","            )\n","            \n","            x = self.decoder[_ + 1](concat_layer)\n","            \n","        # Return predicted logits    \n","        return self.output_conv(x)"]},{"cell_type":"markdown","metadata":{},"source":["<a id='4.3'></a>\n","### Generate U-Net Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:23.819262Z","iopub.status.busy":"2024-01-08T10:27:23.818555Z","iopub.status.idle":"2024-01-08T10:27:24.295136Z","shell.execute_reply":"2024-01-08T10:27:24.294355Z","shell.execute_reply.started":"2024-01-08T10:27:23.819227Z"},"trusted":true},"outputs":[],"source":["# Define U-Net Params\n","unet_params = {\n","    'in_channels'    : 3,\n","    'out_channels'   : 1,\n","    'block_sizes'    : (64, 128, 256, 512)\n","}\n","\n","# Generate Model & Push to Device\n","unet_model = UNetModel(**unet_params).to(CFG.DEVICE)\n","\n","# If using GPU T4 x2 setup, use this:\n","if CFG.NUM_DEVICES > 1:\n","    unet_model = nn.DataParallel(unet_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:25.424928Z","iopub.status.busy":"2024-01-08T10:27:25.424562Z","iopub.status.idle":"2024-01-08T10:27:27.374043Z","shell.execute_reply":"2024-01-08T10:27:27.373038Z","shell.execute_reply.started":"2024-01-08T10:27:25.424898Z"},"trusted":true},"outputs":[],"source":["# View model summary\n","summary(\n","    model=unet_model, \n","    input_size=(CFG.BATCH_SIZE, CFG.CHANNELS, CFG.WIDTH, CFG.HEIGHT),\n","    col_names=[\"output_size\", \"num_params\", \"trainable\"],\n","    col_width=20,\n","    row_settings=[\"var_names\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:27.441549Z","iopub.status.busy":"2024-01-08T10:27:27.440627Z","iopub.status.idle":"2024-01-08T10:27:28.095933Z","shell.execute_reply":"2024-01-08T10:27:28.094978Z","shell.execute_reply.started":"2024-01-08T10:27:27.441515Z"},"trusted":true},"outputs":[],"source":["# Generate Model Computation Graph\n","model_graph = draw_graph(\n","    UNetModel(), \n","    input_size=(1, CFG.CHANNELS, CFG.WIDTH, CFG.HEIGHT), \n","    expand_nested=True\n",")\n","\n","# View Model Architecture\n","model_graph.visual_graph"]},{"cell_type":"markdown","metadata":{},"source":["<a id='4.4'></a>\n","### Initiate Model Loss, Optimizer & LR Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:36.233262Z","iopub.status.busy":"2024-01-08T10:27:36.232264Z","iopub.status.idle":"2024-01-08T10:27:36.239608Z","shell.execute_reply":"2024-01-08T10:27:36.238715Z","shell.execute_reply.started":"2024-01-08T10:27:36.233229Z"},"trusted":true},"outputs":[],"source":["# Define Loss Function\n","loss_fn = nn.BCEWithLogitsLoss()\n","\n","# Define Optimizer\n","optimizer = torch.optim.AdamW(\n","    unet_model.parameters(),\n","    lr=CFG.LR\n",")\n","\n","# Define Scheduler\n","scheduler = lr_scheduler.ReduceLROnPlateau(\n","    optimizer=optimizer, \n","    mode='min',\n","    patience=CFG.PATIENS,\n","    verbose=True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<a id='4.5'></a>\n","### Train U-Net Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T10:27:38.43689Z","iopub.status.busy":"2024-01-08T10:27:38.436265Z","iopub.status.idle":"2024-01-08T11:16:01.240965Z","shell.execute_reply":"2024-01-08T11:16:01.239562Z","shell.execute_reply.started":"2024-01-08T10:27:38.436856Z"},"trusted":true},"outputs":[],"source":["print('Training U-Net Model')\n","print(f'Train on {len(train_df)} samples, validate on {len(val_df)} samples.')\n","print('----------------------------------')\n","\n","# Generate training session config \n","session_config = {\n","    'model'               : unet_model,\n","    'train_dataloader'    : train_loader,\n","    'eval_dataloader'     : val_loader,\n","    'optimizer'           : optimizer,\n","    'scheduler'           : scheduler,\n","    'loss_fn'             : loss_fn,\n","    'epochs'              : CFG.EPOCHS,\n","    'device'              : CFG.DEVICE\n","}\n","\n","# Execute Training Session\n","unet_session_history = train(**session_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T15:41:35.505271Z","iopub.status.busy":"2023-12-15T15:41:35.504959Z","iopub.status.idle":"2023-12-15T15:41:35.510562Z","shell.execute_reply":"2023-12-15T15:41:35.509642Z","shell.execute_reply.started":"2023-12-15T15:41:35.505239Z"},"trusted":true},"outputs":[],"source":["# Create Model directory\n","model_name = 'unet_model'\n","model_path = '/kaggle/working/model/'\n","os.mkdir(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T15:41:35.511988Z","iopub.status.busy":"2023-12-15T15:41:35.511692Z","iopub.status.idle":"2023-12-15T15:41:35.73544Z","shell.execute_reply":"2023-12-15T15:41:35.734521Z","shell.execute_reply.started":"2023-12-15T15:41:35.511964Z"},"trusted":true},"outputs":[],"source":["# Save Model \n","torch.save(unet_model, model_path + model_name + '.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:06.022654Z","iopub.status.busy":"2024-01-08T11:16:06.022275Z","iopub.status.idle":"2024-01-08T11:16:12.550875Z","shell.execute_reply":"2024-01-08T11:16:12.549534Z","shell.execute_reply.started":"2024-01-08T11:16:06.022617Z"},"trusted":true},"outputs":[],"source":["# Generate Test Masks\n","unet_test_masks = predict(\n","    unet_model, test_loader, \n","    CFG.DEVICE, threshold=0.5\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<center><div style='color:#ffffff;\n","           display:inline-block;\n","           padding: 5px 5px 5px 5px;\n","           border-radius:5px;\n","           background-color:#78D1E1;\n","           font-size:100%;'><a href=#toc style='text-decoration: none; color:#03001C;'>⬆️ Back To Top</a></div></center>\n","\n","<a id='5'></a>\n","# 5 | Performance Analysis\n","<div style=\"padding: 4px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://i.postimg.cc/j2bBmHWx/Py-Torch-Gradient.jpg); background-size: 100% auto;\"></div>\n","\n","<br>\n","\n","\n","<a id='5.1'></a>\n","### Plot Training Session Records"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:12.554344Z","iopub.status.busy":"2024-01-08T11:16:12.553481Z","iopub.status.idle":"2024-01-08T11:16:12.56798Z","shell.execute_reply":"2024-01-08T11:16:12.56699Z","shell.execute_reply.started":"2024-01-08T11:16:12.5543Z"},"trusted":true},"outputs":[],"source":["def plot_training_curves(history, fig_size=(20, 10)):\n","    \n","    loss = np.array(history['loss'])\n","    val_loss = np.array(history['eval_loss'])\n","\n","    dice_coeff = np.array(history['dice_score'])\n","    val_dice_coeff = np.array(history['eval_dice_score'])\n","\n","    epochs = range(len(history['loss']))\n","\n","    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=fig_size)\n","\n","    # Plot loss\n","    ax1.plot(epochs, loss, label='training_loss', marker='o', color='C5');\n","    ax1.plot(epochs, val_loss, label='eval_loss', marker='o', color='C6');\n","    \n","    # Fill area between losses\n","    ax1.fill_between(epochs, loss, val_loss, where=(loss > val_loss), color='C5', alpha=0.4, interpolate=True);\n","    ax1.fill_between(epochs, loss, val_loss, where=(loss < val_loss), color='C6', alpha=0.4, interpolate=True);\n","\n","    # Add Text & Formats\n","    ax1.set_title('Loss (Lower Means Better)', fontsize=22);\n","    ax1.set_xlabel('Epochs', fontsize=18);\n","    ax1.set_ylabel('Loss', fontsize=18);\n","    ax1.tick_params(axis='both', which='major', labelsize=14);\n","    ax1.legend(fontsize=14);\n","\n","    # Plot metric\n","    ax2.plot(epochs, dice_coeff, label='training_dice_score', marker='o', color='C5');\n","    ax2.plot(epochs, val_dice_coeff, label='eval_dice_score', marker='o', color='C6');\n","    \n","    # Fill area between metrics\n","    ax2.fill_between(epochs, dice_coeff, val_dice_coeff, where=(dice_coeff > val_dice_coeff), color='C5', alpha=0.4, interpolate=True);\n","    ax2.fill_between(epochs, dice_coeff, val_dice_coeff, where=(dice_coeff < val_dice_coeff), color='C6', alpha=0.4, interpolate=True);\n","    \n","    # Add Text & Formats\n","    ax2.set_title('Dice Score (Higher Means Better)', fontsize=22);\n","    ax2.set_xlabel('Epochs', fontsize=18);\n","    ax2.set_ylabel('Dice Score', fontsize=18);\n","    ax2.tick_params(axis='both', which='major', labelsize=14);\n","    ax2.legend(fontsize=14);\n","    \n","    sns.despine();\n","    \n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T15:41:41.980428Z","iopub.status.busy":"2023-12-15T15:41:41.980105Z","iopub.status.idle":"2023-12-15T15:41:42.003635Z","shell.execute_reply":"2023-12-15T15:41:42.002767Z","shell.execute_reply.started":"2023-12-15T15:41:41.980395Z"},"trusted":true},"outputs":[],"source":["# Convert U-Net history dict to DataFrame\n","unet_session_history_df = pd.DataFrame(unet_session_history)\n","unet_session_history_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T15:41:42.005131Z","iopub.status.busy":"2023-12-15T15:41:42.004832Z","iopub.status.idle":"2023-12-15T15:41:42.835048Z","shell.execute_reply":"2023-12-15T15:41:42.834097Z","shell.execute_reply.started":"2023-12-15T15:41:42.005108Z"},"trusted":true},"outputs":[],"source":["# Plot U-Net Session Training History \n","plot_training_curves(\n","    unet_session_history,\n","    fig_size=(20, 20)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","<h3>Observation</h3>\n","We see that our model was able to converge to a lower loss for both training and validation sets. We also observe that the model seems to have reached a plateau on both the training and validation dice scores.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id='5.2'></a>\n","### Generate & Inspect Semantic Segmentation Metrics\n","\n","To understand what our model is producing, we need to analyse relevant metrics for segmentation. So, to inspect our model's segmentation performance we will inspect the following metrics:\n","\n","\n","- <b>Accuracy</b>\n","\n","> The pixel accuracy is the number of correctly classified pixels found in the generated mask. Although it is the simplist metric to compute, it is not the most appropriate metric to analyse in the case of segmentation as most pixels in a segmentation mask will be extremely imbalanced (e.g. a 224x224 mask may only have 5% of pixels which are not blank). This metric will often report an accuracy >90%, but the actual segmentation performance may be worse.\n","\n","<br>\n","\n","- <b>Dice Score/Coefficient</b>\n","\n","> <center>  $\\displaystyle Dice Score = 2 \\frac{|y_{target} \\bigcap y_{pred}|}{|y_{target}| +  |y_{pred}|}$ </center>\n","<br>\n","> The Dice coefficient is a popular segmentation metric which measures the overlap between two samples. The metric generates a score ranging between 0 and 1 inclusively where a Dice score of 1 indicating perfect overlap and a score of 0 indicating no overlap. The Dice score is obtained by computing the ratio of the intersection) of the two samples and sum of their element-wise sum. \n","\n","<br>\n","\n","- <b>Jaccard Index (IoU)</b>\n","\n","> <center> $\\displaystyle IoU = \\frac{|y_{target} \\bigcap y_{pred}|}{|y_{target} \\bigcup y_{pred}|}$ </center>\n","<br>\n","> The Jaccard Index (also known as Intersection over Union (IoU)) is aa useful metric for evaluating a semantic segmentation model. The IoU is the overlap between the predicted segmentation mask and the actual mask divided by the union area. The IoU ranges between 0-1 with 0 indicating no overlap and 1 indicating a perfect overlap between the actual mask and the generated segmentation mask.\n","\n","In this section we will also consider the precision and recall metrics. For more information, kindly see the following:\n","> - [Statology | A Simple Explanation of the Jaccard Similarity Index](https://www.statology.org/jaccard-similarity/)\n","> - [Jeremy Jordan | Evaluating image segmentation models](https://www.jeremyjordan.me/evaluating-image-segmentation-models/)\n","> - [Jeremy Jordan | An overview of semantic image segmentation](https://www.jeremyjordan.me/semantic-segmentation/)\n","> - [Precision and Recall | Essential Metrics for Machine Learning (2023 Update)](https://www.analyticsvidhya.com/blog/2020/09/precision-recall-machine-learning/#What_is_Precision?)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:14.99176Z","iopub.status.busy":"2024-01-08T11:16:14.991093Z","iopub.status.idle":"2024-01-08T11:16:14.999675Z","shell.execute_reply":"2024-01-08T11:16:14.998551Z","shell.execute_reply.started":"2024-01-08T11:16:14.991718Z"},"trusted":true},"outputs":[],"source":["# def accuracy(y_true, y_pred):\n","#     intersection = (y_true * y_pred).sum()\n","#     union = (y_true + y_pred).sum() - intersection\n","#     xor = (y_true == y_pred).sum()\n","    \n","#     return (xor / (union + xor - intersection))\n","\n","\n","def precision_(y_true, y_pred):\n","    intersection = (y_true * y_pred).sum()\n","    total_predicted_pixels = y_pred.sum()\n","    return (intersection / total_predicted_pixels).mean()\n","\n","\n","def recall_(y_true, y_pred):\n","    intersection = (y_true * y_pred).sum()\n","    total_true_pixels = y_true.sum()\n","    return (intersection / total_true_pixels).mean()\n","\n","\n","def dice_score(y_true, y_pred):\n","    eps = 1e-8\n","    intersection = (y_true * y_pred).sum()\n","    summation = (y_true + y_pred).sum()\n","    \n","    return ((2 * intersection) / (summation + eps))\n","\n","\n","def jaccard_index(y_true, y_pred):\n","    eps = 1e-8\n","    intersection = (y_true * y_pred).sum()\n","    union = (y_true + y_pred).sum() - intersection\n","    \n","    return (intersection / (union + eps))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:17.78182Z","iopub.status.busy":"2024-01-08T11:16:17.781427Z","iopub.status.idle":"2024-01-08T11:16:17.792907Z","shell.execute_reply":"2024-01-08T11:16:17.791967Z","shell.execute_reply.started":"2024-01-08T11:16:17.781788Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(\n","    model:nn.Module, \n","    sample_loader:torch.utils.data.DataLoader,\n","    device:torch.device) -> np.ndarray:\n","    \n","    # Initiate Metrics Dict\n","    metrics = {\n","        'accuracy'      : [],\n","        'precision'     : [],\n","        'recall'        : [],\n","        'dice_score'    : [],\n","        'IoU'           : []\n","    }\n","    \n","    # Set model into eval mode\n","    model.eval()\n","    \n","    # Active inferene context manager\n","    with torch.inference_mode():\n","        # Execute eval loop over dataloader\n","        for batch, (X, y) in enumerate(tqdm(sample_loader)):\n","            # Load data onto target device\n","            X, y = X.to(device), y.to(device)\n","\n","            # Feed-forward Input\n","            y_pred = model(X) \n","            \n","            # Generate Predicted Masks\n","            predicted_class = torch.sigmoid(y_pred)\n","            predicted_class = (predicted_class > 0.3).float()\n","            \n","            # Compute Batch Metrics For Each Mask\n","            for true_mask, pred_mask in zip(y, predicted_class):\n","                acc = ((true_mask == pred_mask).sum() / torch.numel(true_mask)).cpu().item()\n","                prec = precision_(true_mask, pred_mask).cpu().item()\n","                rec = recall_(true_mask, pred_mask).cpu().item()\n","                dice = dice_score(true_mask, pred_mask).cpu().item()\n","                iou = jaccard_index(true_mask, pred_mask).cpu().item()\n","                \n","                # Record metrics\n","                metrics['accuracy'].append(acc)\n","                metrics['precision'].append(prec)\n","                metrics['recall'].append(rec)\n","                metrics['dice_score'].append(dice)\n","                metrics['IoU'].append(iou)\n","        \n","    return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:20.499558Z","iopub.status.busy":"2024-01-08T11:16:20.498621Z","iopub.status.idle":"2024-01-08T11:16:26.753957Z","shell.execute_reply":"2024-01-08T11:16:26.75283Z","shell.execute_reply.started":"2024-01-08T11:16:20.499522Z"},"trusted":true},"outputs":[],"source":["# Generate Segmentation Metrics\n","unet_metrics = compute_metrics(\n","    unet_model, test_loader, CFG.DEVICE\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:26.757667Z","iopub.status.busy":"2024-01-08T11:16:26.757255Z","iopub.status.idle":"2024-01-08T11:16:26.8023Z","shell.execute_reply":"2024-01-08T11:16:26.801368Z","shell.execute_reply.started":"2024-01-08T11:16:26.757624Z"},"trusted":true},"outputs":[],"source":["# Create copy of test df\n","unet_test_df = test_df.copy()\n","\n","# Concatenate Metrics onto copied df\n","unet_test_df = pd.concat(\n","    (unet_test_df, pd.DataFrame(unet_metrics)), \n","    axis=1\n",")\n","\n","# Generate diagnosis labels\n","unet_test_df['model_diagnosis'] = [\n","    int(mask.max()) for mask in unet_test_masks\n","]\n","\n","# View df\n","unet_test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:26.803614Z","iopub.status.busy":"2024-01-08T11:16:26.803339Z","iopub.status.idle":"2024-01-08T11:16:26.82325Z","shell.execute_reply":"2024-01-08T11:16:26.822511Z","shell.execute_reply.started":"2024-01-08T11:16:26.803589Z"},"trusted":true},"outputs":[],"source":["# Get segmentation metrics for all samples\n","overall_metrics = dict(\n","    unet_test_df[unet_metrics.keys()]\n","    .mean()\n",")\n","\n","# Get segmentation metrics for non-diagnosed samples\n","non_diagnosed_metrics = dict(\n","    unet_test_df[\n","        unet_test_df['diagnosis'] == 0\n","    ][unet_metrics.keys()].mean()\n",")\n","\n","# Get segmentation metrics for diagnosed samples\n","diagnosed_metrics = dict(\n","    unet_test_df[\n","        unet_test_df['diagnosis'] == 1\n","    ][unet_metrics.keys()].mean()\n",")\n","\n","# Compile metrics into dataframe\n","segmetation_metrics = pd.DataFrame({\n","    'overall_metrics': overall_metrics,\n","    'non_diagnosed_metrics': non_diagnosed_metrics,\n","    'diagnosed_metrics': diagnosed_metrics,  \n","}).T\n","\n","# View segmetation metrics df\n","segmetation_metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:32.44829Z","iopub.status.busy":"2024-01-08T11:16:32.447912Z","iopub.status.idle":"2024-01-08T11:16:33.010706Z","shell.execute_reply":"2024-01-08T11:16:33.009806Z","shell.execute_reply.started":"2024-01-08T11:16:32.448259Z"},"trusted":true},"outputs":[],"source":["# Plot segmentation metrics bar plot\n","ax = segmetation_metrics.plot(\n","    kind=\"bar\", rot=0,\n","    figsize=(20, 10)\n",")\n","\n","# Add legend\n","ax.legend(bbox_to_anchor=(1.0, 1.0), fontsize=14)\n","\n","# Display bar values\n","for p in ax.patches:\n","    bar_value = p.get_height()\n","    text = '0.0' if bar_value==0 else f'{bar_value:.4f}'\n","    ax.annotate(\n","        text, \n","        (p.get_x() * 1.005, p.get_height() * 1.005 + 0.01), \n","        fontsize=12\n","    )\n","\n","# Update axes tick parameters\n","ax.tick_params(\n","    axis='both', which='major', \n","    labelsize=16\n",");\n","\n","# Rotate x-axis ticks\n","ax.tick_params(\n","    axis='x', which='major', \n","    labelsize=16, rotation=45\n",");\n","\n","# Add title & remove top and right borders w. sns.despine\n","plt.title('Semantic Segmentation Metrics', fontsize=20);\n","sns.despine();"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","<h3>Observation</h3>\n","We can observe a stark difference between the validation average dice score (~90%) and the test average dice score (~82%) for the diagnosed cases. This implies that our model is able to produce good semantic segmentation masks, but there is still room for improvement.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id='5.3'></a>\n","### Generate Diagnosis Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:38.377321Z","iopub.status.busy":"2024-01-08T11:16:38.376976Z","iopub.status.idle":"2024-01-08T11:16:38.385198Z","shell.execute_reply":"2024-01-08T11:16:38.384122Z","shell.execute_reply.started":"2024-01-08T11:16:38.377294Z"},"trusted":true},"outputs":[],"source":["def plot_confusion_matrix(y_true, y_pred, classes='auto', figsize=(10, 10), text_size=12): \n","    # Generate confusion matrix \n","    cm = confusion_matrix(y_true, y_pred)\n","    \n","    # Set plot size\n","    plt.figure(figsize=figsize)\n","\n","    # Create confusion matrix heatmap\n","    disp = sns.heatmap(\n","        cm, annot=True, cmap='Greens',\n","        annot_kws={\"size\": text_size}, fmt='g',\n","        linewidths=0.5, linecolor='black', clip_on=False,\n","        xticklabels=classes, yticklabels=classes)\n","    \n","    # Set title and axis labels\n","    disp.set_title('Confusion Matrix', fontsize=24)\n","    disp.set_xlabel('Predicted Label', fontsize=20) \n","    disp.set_ylabel('True Label', fontsize=20)\n","    plt.yticks(rotation=0) \n","\n","    # Plot confusion matrix\n","    plt.show()\n","    \n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:42.111088Z","iopub.status.busy":"2024-01-08T11:16:42.110695Z","iopub.status.idle":"2024-01-08T11:16:42.116056Z","shell.execute_reply":"2024-01-08T11:16:42.115014Z","shell.execute_reply.started":"2024-01-08T11:16:42.111058Z"},"trusted":true},"outputs":[],"source":["# Get Test True Diagnosis Labels\n","test_labels = unet_test_df['diagnosis'].to_numpy()\n","\n","# Get Test Predicted Diagnosis Labels\n","unet_predictions = unet_test_df['model_diagnosis'].to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:43.711479Z","iopub.status.busy":"2024-01-08T11:16:43.710687Z","iopub.status.idle":"2024-01-08T11:16:44.050875Z","shell.execute_reply":"2024-01-08T11:16:44.050103Z","shell.execute_reply.started":"2024-01-08T11:16:43.711447Z"},"trusted":true},"outputs":[],"source":["# Plot Confusion Matrix\n","plot_confusion_matrix(\n","    test_labels, \n","    unet_predictions, \n","    figsize=(12, 8),  \n","    classes=['NORMAL', 'TUMOR']\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<a id='5.4'></a>\n","### Inspect Diagnosis Classification Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:48.176985Z","iopub.status.busy":"2024-01-08T11:16:48.176369Z","iopub.status.idle":"2024-01-08T11:16:48.195299Z","shell.execute_reply":"2024-01-08T11:16:48.194259Z","shell.execute_reply.started":"2024-01-08T11:16:48.176953Z"},"trusted":true},"outputs":[],"source":["print(\n","    classification_report(\n","        test_labels, \n","        unet_predictions, \n","        target_names=['NORMAL', 'TUMOR']\n","))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:56.272221Z","iopub.status.busy":"2024-01-08T11:16:56.271872Z","iopub.status.idle":"2024-01-08T11:16:56.280869Z","shell.execute_reply":"2024-01-08T11:16:56.279706Z","shell.execute_reply.started":"2024-01-08T11:16:56.272194Z"},"trusted":true},"outputs":[],"source":["def generate_performance_scores(y_true, y_pred, log=True):\n","    \n","    model_accuracy = accuracy_score(y_true, y_pred)\n","    model_precision, model_recall, model_f1, _ = (\n","        precision_recall_fscore_support(\n","            y_true, y_pred, average=\"weighted\"\n","        )\n","    )    \n","    model_matthews_corrcoef = matthews_corrcoef(y_true, y_pred)\n","    \n","    if log:\n","        print('=============================================')\n","        print(f'\\nPerformance Metrics:\\n')\n","        print('=============================================')\n","        print(f'accuracy_score:\\t\\t{model_accuracy:.4f}\\n')\n","        print('_____________________________________________')\n","        print(f'precision_score:\\t{model_precision:.4f}\\n')\n","        print('_____________________________________________')\n","        print(f'recall_score:\\t\\t{model_recall:.4f}\\n')\n","        print('_____________________________________________')\n","        print(f'f1_score:\\t\\t{model_f1:.4f}\\n')\n","        print('_____________________________________________')\n","        print(f'matthews_corrcoef:\\t{model_matthews_corrcoef:.4f}\\n')\n","        print('=============================================')\n","    \n","    preformance_scores = {\n","        'accuracy_score'       : model_accuracy,\n","        'precision_score'      : model_precision,\n","        'recall_score'         : model_recall,\n","        'f1_score'             : model_f1,\n","        'matthews_corrcoef'    : model_matthews_corrcoef\n","    }\n","    return preformance_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:16:59.406322Z","iopub.status.busy":"2024-01-08T11:16:59.405615Z","iopub.status.idle":"2024-01-08T11:16:59.416664Z","shell.execute_reply":"2024-01-08T11:16:59.415805Z","shell.execute_reply.started":"2024-01-08T11:16:59.406285Z"},"trusted":true},"outputs":[],"source":["# Generate U-Net model classification performance scores\n","unet_model_performance = generate_performance_scores(\n","    test_labels, unet_predictions, log=True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","<h3>Observation</h3>\n","Our model achieved an f1-score of ~96% for tumour detection, which implies that the model can make quality distinguishments between normal and tumour MRI cases (supported by a high Matthew's Correlation Coefficient (MCC) of ~93% achieved by the model).\n","\n","<br><br>\n","The MRI error rate for diagnosing tumour presence is approximately 3%. Since the test set consists of 767 samples, these incorrectly assessed samples should amount to ~23 in total (see the confusion matrix displayed above). In other words, for every 1000 MRI samples we should expect +/- 30 incorrectly diagnosed samples.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id='5.5'></a>\n","### View Diagnosed Sample Prediction Masks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:31:53.341498Z","iopub.status.busy":"2024-01-08T11:31:53.340498Z","iopub.status.idle":"2024-01-08T11:31:53.355204Z","shell.execute_reply":"2024-01-08T11:31:53.35417Z","shell.execute_reply.started":"2024-01-08T11:31:53.341459Z"},"trusted":true},"outputs":[],"source":["def view_multiple_predictions(\n","    model, ds, count=10, \n","    color_map='rgb', \n","    fig_size=(14, 10), \n","    title_size=16):\n","    \n","    # Select random samples\n","    idx = random.sample(\n","        list(range(len(ds))), \n","        count\n","    )\n","    \n","    # Initialise figure\n","    fig = plt.figure(figsize=fig_size);\n","    fig.tight_layout();\n","    fig.subplots_adjust(top=0.95);\n","    \n","    # Plot Samples \n","    for row, _ in enumerate(idx):\n","        image, mask = ds[_]\n","        idx = 3 * (row + 1)\n","        \n","        # Plot MRI Image\n","        plt.subplot(count+1, 3, idx + 1);\n","        plt.title(f'MRI Image', fontsize=title_size);\n","        if color_map=='rgb':\n","            plt.imshow(image.permute(1, 2, 0))\n","        else:\n","            plt.imshow(image.permute(1, 2, 0), cmap=color_map)\n","\n","        # Plot Mask\n","        plt.subplot(count+1, 3, idx + 2);\n","        plt.title(f'True Mask', fontsize=title_size)\n","        \n","        gen_mask = np.dstack([mask[0]*0.1, mask[0]*0.45, mask[0]*0.1])\n","        plt.imshow(image.permute(1, 2, 0) + gen_mask);\n","\n","        # Generate predicted mask\n","        mri_input = torch.unsqueeze(\n","            torch.tensor(image), dim=0\n","        )\n","        \n","        # Set inferene context manager to active for predictions\n","        with torch.inference_mode():\n","            pred_mask = model(mri_input)\n","            pred_mask = torch.sigmoid(pred_mask).cpu()\n","            pred_mask = (pred_mask > 0.5) #threshold of 0.5\n","\n","        # Plot Predicted Mask \n","        plt.subplot(count+1, 3, idx + 3);\n","        plt.title(f'Predicted Mask', fontsize=title_size)\n","        \n","        pred_gen_mask = np.dstack([pred_mask[0][0]*0.3, pred_mask[0][0]*0.2, pred_mask[0][0]*0.8])\n","        plt.imshow(image.permute(1, 2, 0)+ pred_gen_mask);\n","\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:17:09.131036Z","iopub.status.busy":"2024-01-08T11:17:09.130387Z","iopub.status.idle":"2024-01-08T11:17:09.138114Z","shell.execute_reply":"2024-01-08T11:17:09.137093Z","shell.execute_reply.started":"2024-01-08T11:17:09.131Z"},"trusted":true},"outputs":[],"source":["# Create Dataset for Diagnosed Sample\n","test_diagnosed_ds = MRISegmetationDataset(\n","    unet_test_df[\n","        unet_test_df['diagnosis'] == 1\n","    ].reset_index(drop=True), \n","    transform=inference_transforms\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T11:31:56.391019Z","iopub.status.busy":"2024-01-08T11:31:56.39059Z","iopub.status.idle":"2024-01-08T11:32:03.195454Z","shell.execute_reply":"2024-01-08T11:32:03.194525Z","shell.execute_reply.started":"2024-01-08T11:31:56.390985Z"},"trusted":true},"outputs":[],"source":["# View Random Samples\n","view_multiple_predictions(\n","    unet_model, test_diagnosed_ds, \n","    count=8, color_map='rgb',\n","    fig_size=(20, 38)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","<h3>Observation</h3>\n","We observe that our model is able to generate good segmentation maps. However, it is clear the it struggles to fully segement the MRI samples without producing artifacts. \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<center><div style='color:#ffffff;\n","           display:inline-block;\n","           padding: 5px 5px 5px 5px;\n","           border-radius:5px;\n","           background-color:#78D1E1;\n","           font-size:100%;'><a href=#toc style='text-decoration: none; color:#03001C;'>⬆️ Back To Top</a></div></center>\n","\n","<a id='conclusion'></a>\n","# <center>Conclusion</center>\n","<div style=\"padding: 4px;color:white;margin:10;font-size:200%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://i.postimg.cc/j2bBmHWx/Py-Torch-Gradient.jpg); background-size: 100% auto;\"></div>\n","\n","<br>\n","\n","In this notebook, we've covered the implementation of the U-Net architecture to train a model for segmenting brain tumors in MRIs. We found that the model achieved a Jaccard Index of ~0.73 and a Dice score of ~0.82 on the test set, which indicates that the model can produce decent quality segmentations, but there is room for improvement.\n","\n","We also discussed the model's capability to generate a diagnosis. We observed that the model achieved an error rate of ~3% for diagnosing normal and tumor cases correctly. This implies that for every 1000 MRI samples, we should expect +/- 30 incorrectly diagnosed samples. Also, we noticed that our model achieved a high Matthew's Correlation Coefficient (MCC) of approximately 93% when diagnosing MRI samples. This indicates that our model exhibits a strong understanding of how to diagnose samples and should be able to effectively diagnose unseen samples.\n","\n","\n","### Suggestions for improving model performance\n","\n","To improve the current results achieved by the model covered in this notebook, the following should be considered:\n","\n","- Using a pre-trained model as a backbone: By using a pre-trained model (such VGG, EfficientNet V2 or DINOv2) as an backbone encoder model, one should be able to achieve improved segmentation and diagnosis performance.\n","\n","- Training for more epochs: More epochs during training may lead to improved results, but will come at the cost of more training time.\n","\n","- Using Ensembles: Ensembling multiple models has shown to be effective in many ML problems as it usually leads to improved results. By training more models for ensembling may lead to improved segmentation results, but will certainly require more training time, and result in increased inference time.\n","\n","The process of detecting brain tumors using AI is challenging and has a very low margin of error. However, if executed accurately, this technology can greatly benefit numerous patients by providing them with the correct diagnosis and timely treatment, potentially saving their lives from fatal outcomes."]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"color:white;padding:35px;color:white;margin:10;font-size:120%;text-align:center;display:fill;border-radius:10px;overflow:hidden;background-image: url(https://i.postimg.cc/j2bBmHWx/Py-Torch-Gradient.jpg); background-size: 100% auto;background-position: 0px 0px;\">\n","    <center>\n","    <span style='color:white'>\n","    <h3><span style='color:white'><b>I hope this notebook serves the community well!</b></span></h3>\n","    <h3><span style='color:white'><b>Thank you for visiting! 🙏</b></span></h3>\n","    </span>\n","    </center>\n","</div>"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":181273,"sourceId":407317,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
